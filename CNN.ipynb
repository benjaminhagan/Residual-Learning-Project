{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses gpu if available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#Downloads datasets\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transform) #Set download to true first time\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform) #Set download to true first time\n",
    "\n",
    "#Split for cross validation\n",
    "train_dataset, validation_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "#Creates DataLoaders for each set\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines Convolutional Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        #Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=2, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        #Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=64, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional layers with ReLU activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #Fully connected layers with ReLU activation\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through a training epoch while displaying performance metrics by batch\n",
    "def train_epoch(network, optimizer, criterion):\n",
    "    network.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for batch_index, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = network(inputs)\n",
    "        num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += num_correct / batch_size\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 500 == 499:\n",
    "            avg_loss_across_batches = running_loss / 500\n",
    "            avg_acc_across_batches = (running_accuracy / 500) * 100\n",
    "            print('Batch{0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0\n",
    "            running_accuracy = 0\n",
    "\n",
    "#Optional method to evaluate performance on validation data\n",
    "def validate_epoch(network, criterion):\n",
    "    network.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = network(inputs)\n",
    "            num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += num_correct / batch_size\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(valloader)\n",
    "    avg_accuracy_across_batches = (running_accuracy / len(valloader)) * 100\n",
    "    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches, avg_accuracy_across_batches))\n",
    "    print('*****************************************')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch500, Loss: 2.284, Accuracy: 15.8%\n",
      "Batch1000, Loss: 1.468, Accuracy: 58.9%\n",
      "Batch1500, Loss: 0.806, Accuracy: 75.9%\n",
      "Batch2000, Loss: 0.589, Accuracy: 82.8%\n",
      "Batch2500, Loss: 0.467, Accuracy: 86.5%\n",
      "Batch3000, Loss: 0.395, Accuracy: 88.3%\n",
      "Batch3500, Loss: 0.367, Accuracy: 89.1%\n",
      "Batch4000, Loss: 0.350, Accuracy: 89.5%\n",
      "Batch4500, Loss: 0.305, Accuracy: 91.1%\n",
      "Batch5000, Loss: 0.301, Accuracy: 90.9%\n",
      "Batch5500, Loss: 0.268, Accuracy: 92.1%\n",
      "Batch6000, Loss: 0.266, Accuracy: 91.5%\n",
      "Val Loss: 0.257, Val Accuracy: 91.9%\n",
      "*****************************************\n",
      "\n",
      "Epoch 2\n",
      "Batch500, Loss: 0.248, Accuracy: 92.2%\n",
      "Batch1000, Loss: 0.229, Accuracy: 93.3%\n",
      "Batch1500, Loss: 0.213, Accuracy: 94.0%\n",
      "Batch2000, Loss: 0.236, Accuracy: 93.1%\n",
      "Batch2500, Loss: 0.219, Accuracy: 93.0%\n",
      "Batch3000, Loss: 0.221, Accuracy: 93.7%\n",
      "Batch3500, Loss: 0.205, Accuracy: 93.8%\n",
      "Batch4000, Loss: 0.200, Accuracy: 94.0%\n",
      "Batch4500, Loss: 0.190, Accuracy: 94.2%\n",
      "Batch5000, Loss: 0.179, Accuracy: 94.4%\n",
      "Batch5500, Loss: 0.178, Accuracy: 94.4%\n",
      "Batch6000, Loss: 0.160, Accuracy: 94.8%\n",
      "Val Loss: 0.183, Val Accuracy: 93.9%\n",
      "*****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sets up CNN, optimizer, and loss function\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "#Trains the CNN\n",
    "num_epochs = 2\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_epoch(cnn, optimizer, criterion)\n",
    "    validate_epoch(cnn, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.91000000000001\n"
     ]
    }
   ],
   "source": [
    "#Verifies accuracy on test data set\n",
    "total_correct = 0\n",
    "for batch_index, data in enumerate(testloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = cnn(inputs)\n",
    "        total_correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "print(f\"Accuracy {(total_correct/len(test_dataset)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 3\n",
      "Guess label: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x239b00d8350>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Shows an image along with a guess and true label\n",
    "images, true_labels = next(test_iter)\n",
    "cnn.train(False)\n",
    "guess_labels = cnn(images.to(device))\n",
    "np_imgs = images.numpy()\n",
    "np_img = np_imgs[0]\n",
    "guess_label = torch.argmax(guess_labels[0]).item()\n",
    "print(f\"True label: {true_labels[0]}\")\n",
    "print(f\"Guess label: {guess_label}\")\n",
    "plt.imshow(np_img.reshape((28,28,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

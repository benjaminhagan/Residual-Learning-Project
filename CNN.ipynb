{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses gpu if available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#Downloads datasets\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transform) #Set download to true first time\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform) #Set download to true first time\n",
    "\n",
    "#Split for cross validation\n",
    "train_dataset, validation_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "#Creates DataLoaders for each set\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines Convolutional Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        #Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        #Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional layers with ReLU activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        #Fully connected layers with ReLU activation\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through a training epoch while displaying performance metrics by batch\n",
    "def train_epoch(network, optimizer, criterion):\n",
    "    network.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for batch_index, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = network(inputs)\n",
    "        num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += num_correct / batch_size\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 500 == 499:\n",
    "            avg_loss_across_batches = running_loss / 500\n",
    "            avg_acc_across_batches = (running_accuracy / 500) * 100\n",
    "            print('Batch{0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0\n",
    "            running_accuracy = 0\n",
    "\n",
    "#Optional method to evaluate performance on validation data\n",
    "def validate_epoch(network, criterion):\n",
    "    network.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = network(inputs)\n",
    "            num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += num_correct / batch_size\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(valloader)\n",
    "    avg_accuracy_across_batches = (running_accuracy / len(valloader)) * 100\n",
    "    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches, avg_accuracy_across_batches))\n",
    "    print('*****************************************')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch500, Loss: 1.905, Accuracy: 42.9%\n",
      "Batch1000, Loss: 0.762, Accuracy: 84.9%\n",
      "Batch1500, Loss: 0.356, Accuracy: 92.6%\n",
      "Batch2000, Loss: 0.226, Accuracy: 95.3%\n",
      "Batch2500, Loss: 0.175, Accuracy: 95.4%\n",
      "Batch3000, Loss: 0.163, Accuracy: 95.7%\n",
      "Batch3500, Loss: 0.137, Accuracy: 96.1%\n",
      "Batch4000, Loss: 0.129, Accuracy: 96.1%\n",
      "Batch4500, Loss: 0.099, Accuracy: 97.5%\n",
      "Batch5000, Loss: 0.103, Accuracy: 96.6%\n",
      "Batch5500, Loss: 0.105, Accuracy: 97.2%\n",
      "Batch6000, Loss: 0.090, Accuracy: 97.1%\n",
      "Val Loss: 0.073, Val Accuracy: 97.9%\n",
      "*****************************************\n",
      "\n",
      "Epoch 2\n",
      "Batch500, Loss: 0.082, Accuracy: 97.7%\n",
      "Batch1000, Loss: 0.069, Accuracy: 98.0%\n",
      "Batch1500, Loss: 0.091, Accuracy: 97.5%\n",
      "Batch2000, Loss: 0.065, Accuracy: 97.8%\n",
      "Batch2500, Loss: 0.076, Accuracy: 97.8%\n",
      "Batch3000, Loss: 0.068, Accuracy: 97.8%\n",
      "Batch3500, Loss: 0.072, Accuracy: 97.5%\n",
      "Batch4000, Loss: 0.070, Accuracy: 98.0%\n",
      "Batch4500, Loss: 0.074, Accuracy: 97.8%\n",
      "Batch5000, Loss: 0.060, Accuracy: 98.2%\n",
      "Batch5500, Loss: 0.061, Accuracy: 98.2%\n",
      "Batch6000, Loss: 0.055, Accuracy: 98.4%\n",
      "Val Loss: 0.060, Val Accuracy: 98.0%\n",
      "*****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sets up CNN, optimizer, and loss function\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "#Trains the CNN\n",
    "num_epochs = 2\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_epoch(cnn, optimizer, criterion)\n",
    "    validate_epoch(cnn, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.42\n"
     ]
    }
   ],
   "source": [
    "#Verifies accuracy on test data set\n",
    "total_correct = 0\n",
    "for batch_index, data in enumerate(testloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = cnn(inputs)\n",
    "        total_correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "print(f\"Accuracy {(total_correct/len(test_dataset)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 4\n",
      "Guess label: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25e98c04dd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Shows an image along with a guess and true label\n",
    "images, true_labels = next(test_iter)\n",
    "cnn.train(False)\n",
    "guess_labels = cnn(images.to(device))\n",
    "np_imgs = images.numpy()\n",
    "np_img = np_imgs[0]\n",
    "guess_label = torch.argmax(guess_labels[0]).item()\n",
    "print(f\"True label: {true_labels[0]}\")\n",
    "print(f\"Guess label: {guess_label}\")\n",
    "plt.imshow(np_img.reshape((28,28,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

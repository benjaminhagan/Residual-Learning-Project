{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses gpu if available\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "batch_size = 8\n",
    "\n",
    "#Downloads datasets\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=False, transform=transform) #Set download to true first time\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=transform) #Set download to true first time\n",
    "\n",
    "#Split for cross validation\n",
    "train_dataset, validation_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "#Creates DataLoaders for each set\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines Convolutional Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        #Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.AvgPool2d(2,2)\n",
    "\n",
    "        #Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional layers with ReLU activation function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        #Fully connected layers with ReLU activation\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through a training epoch while displaying performance metrics by batch\n",
    "def train_epoch(network, optimizer, criterion):\n",
    "    network.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for batch_index, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = network(inputs)\n",
    "        num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        running_accuracy += num_correct / batch_size\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 500 == 499:\n",
    "            avg_loss_across_batches = running_loss / 500\n",
    "            avg_acc_across_batches = (running_accuracy / 500) * 100\n",
    "            print('Batch{0}, Loss: {1:.3f}, Accuracy: {2:.1f}%'.format(batch_index+1, avg_loss_across_batches, avg_acc_across_batches))\n",
    "            running_loss = 0\n",
    "            running_accuracy = 0\n",
    "\n",
    "#Optional method to evaluate performance on validation data\n",
    "def validate_epoch(network, criterion):\n",
    "    network.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = network(inputs)\n",
    "            num_correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            running_accuracy += num_correct / batch_size\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(valloader)\n",
    "    avg_accuracy_across_batches = (running_accuracy / len(valloader)) * 100\n",
    "    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches, avg_accuracy_across_batches))\n",
    "    print('*****************************************')\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Batch500, Loss: 1.868, Accuracy: 43.9%\n",
      "Batch1000, Loss: 0.744, Accuracy: 86.2%\n",
      "Batch1500, Loss: 0.324, Accuracy: 93.3%\n",
      "Batch2000, Loss: 0.214, Accuracy: 94.8%\n",
      "Batch2500, Loss: 0.182, Accuracy: 94.7%\n",
      "Batch3000, Loss: 0.154, Accuracy: 95.8%\n",
      "Batch3500, Loss: 0.126, Accuracy: 96.5%\n",
      "Batch4000, Loss: 0.110, Accuracy: 96.8%\n",
      "Batch4500, Loss: 0.113, Accuracy: 96.6%\n",
      "Batch5000, Loss: 0.098, Accuracy: 97.1%\n",
      "Batch5500, Loss: 0.079, Accuracy: 97.8%\n",
      "Batch6000, Loss: 0.083, Accuracy: 97.5%\n",
      "Val Loss: 0.087, Val Accuracy: 97.5%\n",
      "*****************************************\n",
      "\n",
      "Epoch 2\n",
      "Batch500, Loss: 0.083, Accuracy: 97.7%\n",
      "Batch1000, Loss: 0.085, Accuracy: 97.4%\n",
      "Batch1500, Loss: 0.066, Accuracy: 98.0%\n",
      "Batch2000, Loss: 0.063, Accuracy: 98.2%\n",
      "Batch2500, Loss: 0.065, Accuracy: 98.1%\n",
      "Batch3000, Loss: 0.079, Accuracy: 97.6%\n",
      "Batch3500, Loss: 0.053, Accuracy: 98.6%\n",
      "Batch4000, Loss: 0.065, Accuracy: 98.0%\n",
      "Batch4500, Loss: 0.057, Accuracy: 98.2%\n",
      "Batch5000, Loss: 0.068, Accuracy: 98.0%\n",
      "Batch5500, Loss: 0.063, Accuracy: 98.0%\n",
      "Batch6000, Loss: 0.062, Accuracy: 98.2%\n",
      "Val Loss: 0.055, Val Accuracy: 98.2%\n",
      "*****************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sets up CNN, optimizer, and loss function\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "#Trains the CNN\n",
    "num_epochs = 2\n",
    "for i in range(num_epochs):\n",
    "    print(f\"Epoch {i+1}\")\n",
    "    train_epoch(cnn, optimizer, criterion)\n",
    "    validate_epoch(cnn, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 98.68\n"
     ]
    }
   ],
   "source": [
    "#Verifies accuracy on test data set\n",
    "total_correct = 0\n",
    "cnn.train(False)\n",
    "for batch_index, data in enumerate(testloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = cnn(inputs)\n",
    "        total_correct += torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "print(f\"Accuracy {(total_correct/len(test_dataset)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn, 'ShallowCNNParams.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads previously trained models\n",
    "with torch.serialization.safe_globals([CNN]):\n",
    "    cnn = torch.load('ShallowCNNParams.pth', weights_only=False)\n",
    "cnn.to(device)\n",
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 9\n",
      "Guess label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d4cd5c2f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Shows an image along with a guess and true label\n",
    "images, true_labels = next(test_iter)\n",
    "cnn.train(False)\n",
    "guess_labels = cnn(images.to(device))\n",
    "np_imgs = images.numpy()\n",
    "np_img = np_imgs[0]\n",
    "guess_label = torch.argmax(guess_labels[0]).item()\n",
    "print(f\"True label: {true_labels[0]}\")\n",
    "print(f\"Guess label: {guess_label}\")\n",
    "plt.imshow(np_img.reshape((28,28,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
